---
title: "Assignment 1 - Language development in autistic and neurotypical children"
output: html_document
date: "2022-08-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
remove.packages(c("Rcpp","dplyr","rlang"))
install.packages(c("Rcpp","dplyr","rlang"))
library(tidyverse)
library(brms)
library(gridExtra)
library(cmdstanr)
library(tidymodels)
```

# Assignment 1  - Language development in autistic and neurotypical children

## Quick recap
Autism Spectrum Disorder is often related to language impairment. However, this phenomenon has rarely been empirically traced in detail: i) relying on actual naturalistic language production, ii) over extended periods of time.

We therefore videotaped circa 30 kids with ASD and circa 30 comparison kids (matched by linguistic performance at visit 1) for ca. 30 minutes of naturalistic interactions with a parent. We repeated the data collection 6 times per kid, with 4 months between each visit. We transcribed the data and counted: 
i) the amount of words that each kid uses in each video. Same for the parent.
ii) the amount of unique words that each kid uses in each video. Same for the parent.
iii) the amount of morphemes per utterance (Mean Length of Utterance) displayed by each child in each video. Same for the parent. 

This data is in the file you prepared in the previous class, but you can also find it here:https://www.dropbox.com/s/d6eerv6cl6eksf3/data_clean.csv?dl=0


## The structure of the assignment

We will be spending a few weeks with this assignment. In particular, we will:

Part 1) simulate data in order to better understand the model we need to build, and to better understand how much data we would have to collect to run a meaningful study (precision analysis)

Part 2) analyze our empirical data and interpret the inferential results

Part 3) use your model to predict the linguistic trajectory of new children and assess the performance of the model based on that.

As you work through these parts, you will have to produce a written document (separated from the code) answering the following questions:

Q1 - Briefly describe your simulation process, its goals, and what you have learned from the simulation. Add at least a plot showcasing the results of the simulation. Make a special note on sample size considerations: how much data do you think you will need? what else could you do to increase the precision of your estimates?

Q2 - Briefly describe the empirical data and how they compare to what you learned from the simulation (what can you learn from them?). Briefly describe your model(s) and model quality. Report the findings: how does development differ between autistic and neurotypical children (N.B. remember to report both population and individual level findings)? which additional factors should be included in the model? Add at least one plot showcasing your findings.

Q3 - Given the model(s) from Q2, how well do they predict the data? Discuss both in terms of absolute error in training vs testing; and in terms of characterizing the new kids' language development as typical or in need of support.


Below you can find more detailed instructions for each part of the assignment.

## Part 1 - Simulating data

Before we even think of analyzing the data, we should make sure we understand the problem, and we plan the analysis. To do so, we need to simulate data and analyze the simulated data (where we know the ground truth).

In particular, let's imagine we have n autistic and n neurotypical children. We are simulating their average utterance length (Mean Length of Utterance or MLU) in terms of words, starting at Visit 1 and all the way to Visit 6.
In other words, we need to define a few parameters:
- average MLU for ASD (population mean) at Visit 1 and average individual deviation from that (population standard deviation)
- average MLU for TD (population mean) at Visit 1 and average individual deviation from that (population standard deviation)
- average change in MLU by visit for ASD (population mean) and average individual deviation from that (population standard deviation)
- average change in MLU by visit for TD (population mean) and average individual deviation from that (population standard deviation)
- an error term. Errors could be due to measurement, sampling, all sorts of noise. 

Note that this makes a few assumptions: population means are exact values; change by visit is linear (the same between visit 1 and 2 as between visit 5 and 6). This is fine for the exercise. In real life research, you might want to vary the parameter values much more, relax those assumptions and assess how these things impact your inference.


We go through the literature and we settle for some values for these parameters:
- average MLU for ASD and TD: 1.5 (remember the populations are matched for linguistic ability at first visit)
- average individual variability in initial MLU for ASD 0.5; for TD 0.3 (remember ASD tends to be more heterogeneous)
- average change in MLU for ASD: 0.4; for TD 0.6 (ASD is supposed to develop less)
- average individual variability in change for ASD 0.4; for TD 0.2 (remember ASD tends to be more heterogeneous)
- error is identified as 0.2


The mean is $E(X) = exp(\mu + 1/2 \sigma^2)$
the variance is $Var(X)=exp(2μ+σ^2 )(exp(σ^2)−1)$

```{r}

test_lognorm <- function(mu,sigma,ogmu,ogsigma,error,n){
  z <- 1
  data <- tibble(mu = as.double(seq(1:100)), sigma = as.double(seq(1:100)), inrange =seq(1:100))
  
  while(z!=101){
  values<- rlnorm(n,meanlog = mu, sdlog = sigma)
  
  data[z,1] <-mean(values)
  data[z,2] <-sd(values)
  
  z <- z+1
  }
  
  data <- data %>% 
    mutate(inrange = ifelse((mu>(ogmu-error*ogmu) &
                             mu<(ogmu+error*ogmu) &
                             sigma>(ogsigma-error*ogsigma) &
                             sigma<(ogsigma+error*ogsigma) 
                             
                             ),1,0))
  
  return(mean(data$inrange))
  
  }
```

```{r}
#changing values to lognorm ( found the formula on stack overflow)
mu_asd <- log(1.5^2 / sqrt(0.5^2 + 1.5^2))
mu_td <- log(1.5^2 / sqrt(0.3^2 + 1.5^2))
sigma_asd <-sqrt(log(1 + (0.5^2 / 1.5^2)))
sigma_td <- sqrt(log(1 + (0.3^2 / 1.5^2)))

asd_change <- log(0.4^2 / sqrt(0.4^2 + 0.4^2))
td_change <- log(0.6^2 / sqrt(0.2^2 + 0.6^2))
asd_change_var <-sqrt(log(1 + (0.4^2 / 0.4^2)))
td_change_var <-sqrt(log(1 + (0.2^2 / 0.6^2)))

error <- 0.2
```



```{r}
curve(dlnorm(x, meanlog=mu_td, sdlog=sigma_td), from=0, to=4, col='purple')
curve(dlnorm(x, meanlog=mu_asd, sdlog=sigma_asd), from=0, to=4, col='green', add=TRUE)

curve(dlnorm(x, meanlog=asd_change, sdlog=asd_change_var), from=0, to=2.5, col='black')
curve(dlnorm(x, meanlog=td_change, sdlog=td_change_var), from=0, to=2.5, col='red', add=TRUE)
```

This would mean that on average the difference between ASD and TD participants is 0 at visit 1, 0.2 at visit 2, 0.4 at visit 3, 0.6 at visit 4, 0.8 at visit 5 and 1 at visit 6.

With these values in mind, simulate data, plot the data (to check everything is alright); and set up an analysis pipeline.
## simulate

```{r}
set.seed(3)

n <- 30
simdata3 <- tibble(group = rep(c("asd","td"),each=n*6),
                   visit = rep(1:6, times = n*2),
                   id = rep((seq(n*2)),each = 6),
                   Ind_Int = ifelse(group == "asd", 
                            rep(rlnorm(n, meanlog = mu_asd ,  sdlog = sigma_asd), each=6),
                            rep(rlnorm(n, meanlog = mu_td, sdlog = sigma_td ),each=6)),
                   Ind_Slope  = ifelse(group == "asd", 
                            rep(rlnorm(n, meanlog = asd_change, sdlog = asd_change_var),each=6),
                            rep(rlnorm(n, meanlog = td_change, sdlog = td_change_var),each=6)),
                   MLU_no_error = Ind_Int+(Ind_Slope*(visit-1)),
                   ror = rnorm(12*n,0,error),
                   MLUr =  MLU_no_error + ror,
                   MLU = ifelse(MLUr < 0,0.001,MLUr)                    
                   )

                     

```
```{r}
plot_1 <- simdata3 %>% 
  filter(group == "asd") %>% 
  ggplot(aes(x=visit,y=MLU))+
  geom_point()+
  geom_smooth(color = "red")+
  ggtitle("ASD")+
  theme_classic()

plot_2 <- simdata3 %>% 
  filter(group == "td") %>% 
  ggplot(aes(x=visit,y=MLU))+
  geom_point()+
  geom_smooth()+
  ggtitle("TD")+
  theme_classic()

grid.arrange(plot_1,plot_2,nrow = 1)
```
```{r}
plot_4 <- simdata3 %>% 
  filter(group == "asd") %>% 
  ggplot(aes(x=MLU))+
  geom_histogram(binwidth = .1, color = "red", fill = "white")+
  ggtitle("ASD mlu per visit")+
  theme_classic()+
  facet_wrap(~visit)
plot_5 <- simdata3 %>% 
  filter(group == "td") %>% 
  ggplot(aes(x=MLU))+
  geom_histogram(binwidth = .1, color = "Blue", fill = "white")+
  ggtitle("TD mlu per visit")+
  theme_classic()+
  facet_wrap(~visit)

grid.arrange(plot_4,plot_5, nrow = 1)
```
```{r}
simdata3 %>% 
  filter(id == 1) %>% 
  ggplot(aes(x=visit,y=MLU))+
  geom_point()+
  geom_smooth(method = "glm")+
  ggtitle("1")+
  theme_classic()
```
```{r}
simdata3 %>% 
  ggplot(aes(visit, MLU, color = group, group = id)) +
  geom_point()+
  geom_line()+
  theme_classic()

```

Remember the usual bayesian workflow:
## define the formula

```{r}
mlu_f <- bf(MLU ~ 0+group+group:visit+(1+visit|id))
```
We go through the literature and we settle for some values for these parameters:
- average MLU for ASD and TD: 1.5 (remember the populations are matched for linguistic ability at first visit)
- average individual variability in initial MLU for ASD 0.5; for TD 0.3 (remember ASD tends to be more heterogeneous)
- average change in MLU for ASD: 0.4; for TD 0.6 (ASD is supposed to develop less)
- average individual variability in change for ASD 0.4; for TD 0.2 (remember ASD tends to be more heterogeneous)
- error is identified as 0.2
##- define the prior
```{r}
curve(dlnorm(x, meanlog =  0.386, sdlog = 0.2 ), from=0, to=10, col='black')
curve(dlnorm(x, meanlog =0.386, sdlog =0.3), from=0, to=10, col='red', add=TRUE)

```


```{r}
#trial
set.seed(3)

mlu_p_1 <- c(
  prior(lognormal(-0.56,0.32), class = b),
  prior(lognormal(0.386,0.2), class = b, coef = "groupasd"),
  prior(lognormal(0.386,0.2), class = b, coef = "grouptd"),
  prior(lognormal(0,0.2), class = sd, coef = Intercept, group= id),
   prior(lognormal(0,0.2), class = sd, coef = visit, group= id)
)

```

```{r}
#updated based on pp
set.seed(3)

mlu_p_2 <- c(
  prior(lognormal(-0.56,0.42), class = b),
  prior(lognormal(0.386,0.4), class = b, coef = "groupasd"),
  prior(lognormal(0.386,0.4), class = b, coef = "grouptd"),
  prior(lognormal(0,0.6), class = sd, coef = Intercept, group= id),
   prior(lognormal(0,1), class = sd, coef = visit, group= id)
)

```


- prior predictive checks

```{r}
set.seed(3)
mlu_pp_1 <- brm(
  mlu_f,
  data= simdata3,
  prior = mlu_p_2,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  )

  )


pp_check(mlu_pp_1, ndraws = 100)
  
  
```

- fit the model
```{r}
set.seed(3)
mlu_m1 <- brm(
  mlu_f,
  data= simdata3,
  prior = mlu_p_2,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  )

  )

mlu_m2 <- brm(
  mlu_f,
  data= simdata3,
  prior = mlu_p_1,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  )

  )

pp_check(mlu_m1, ndraws = 100)

  
```
- model quality checks: traceplots, divergences, rhat, effective samples

```{r}
set.seed(3)
# Model inference (population estimate) plus actual data
plot(conditional_effects(mlu_m1), points = T)

```

```{r}
set.seed(3)
#Sample the parameters of interest:
post_mlu_m1 <- as_draws_df(mlu_m1)

ggplot(post_mlu_m1) +
  geom_density(aes(prior_b_groupasd), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_groupasd), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept for asd') +
  theme_classic()

ggplot(post_mlu_m1) +
  geom_density(aes(prior_b_grouptd), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_grouptd), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Inercept for td') +
  theme_classic()

ggplot(post_mlu_m1) +
  geom_density(aes(`prior_b_groupasd:visit`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_groupasd:visit`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('asd change by visit') +
  theme_classic()

ggplot(post_mlu_m1) +
  geom_density(aes(`prior_b_grouptd:visit`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_grouptd:visit`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('td change by visit') +
  theme_classic()

ggplot(post_mlu_m1) +
  geom_density(aes(prior_sd_id__Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_id__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individual intercepts') +
  theme_classic()

ggplot(post_mlu_m1) +
  geom_density(aes(prior_sd_id__visit), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_id__visit), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individial slopes') +
  theme_classic()

ggplot(post_mlu_m1) +
  geom_density(aes(prior_cor_id), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(cor_id__Intercept__visit), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('correlation') +
  theme_classic()

```
```{r}
#Sample the parameters of interest:
post_mlu_m1 <- as_draws_df(mlu_m2)
grid.arrange(
ggplot(post_mlu_m1) +
  geom_density(aes(prior_b_groupasd), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_groupasd), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept for asd') +
  theme_classic(),

ggplot(post_mlu_m1) +
  geom_density(aes(prior_b_grouptd), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_grouptd), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Inercept for td') +
  theme_classic(),

ggplot(post_mlu_m1) +
  geom_density(aes(`prior_b_groupasd:visit`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_groupasd:visit`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('asd change by visit') +
  theme_classic(),

ggplot(post_mlu_m1) +
  geom_density(aes(`prior_b_grouptd:visit`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_grouptd:visit`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('td change by visit') +
  theme_classic(),

ggplot(post_mlu_m1) +
  geom_density(aes(prior_sd_id__Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_id__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individual intercepts') +
  theme_classic(),

ggplot(post_mlu_m1) +
  geom_density(aes(prior_sd_id__visit), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_id__visit), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individial slopes') +
  theme_classic(),

ggplot(post_mlu_m1) +
  geom_density(aes(prior_cor_id), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(cor_id__Intercept__visit), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('correlation') +
  theme_classic()
)

```
```{r}
set.seed(3)
hypothesis(mlu_m2, "groupasd:visit < grouptd:visit")
```

```{r}
summary(mlu_m2)
```

- model quality checks: posterior predictive checks, prior-posterior update checks
- model comparison

```{r}

loo_compare(loo(mlu_m1),loo(mlu_m2))
```



Once the pipeline is in place, loop through different sample sizes to assess how much data you would need to collect. N.B. for inspiration on how to set this up, check the tutorials by Kurz that are linked in the syllabus.

BONUS questions for Part 1: what if the difference between ASD and TD was 0? how big of a sample size would you need? What about different effect sizes, and different error terms?

##Balazs looping time

```{r}
sim_data <- function(seed, n) {
  
set.seed(seed)
  
mu_asd <- log(1.5^2 / sqrt(0.5^2 + 1.5^2))
mu_td <- log(1.5^2 / sqrt(0.3^2 + 1.5^2))
sigma_asd <-sqrt(log(1 + (0.5^2 / 1.5^2)))
sigma_td <- sqrt(log(1 + (0.3^2 / 1.5^2)))

asd_change <- log(0.4^2 / sqrt(0.4^2 + 0.4^2))
td_change <- log(0.6^2 / sqrt(0.2^2 + 0.6^2))
asd_change_var <-sqrt(log(1 + (0.4^2 / 0.4^2)))
td_change_var <-sqrt(log(1 + (0.2^2 / 0.6^2)))

error <- 0.2
  

  
 simdata <- tibble(group = rep(c("asd","td"),each=n*6),
                   visit = rep(1:6, times = n*2),
                   id = rep((seq(n*2)),each = 6),
                   Ind_Int = ifelse(group == "asd", 
                            rep(rlnorm(n, meanlog = mu_asd ,  sdlog = sigma_asd), each=6),
                            rep(rlnorm(n, meanlog = mu_td, sdlog = sigma_td ),each=6)),
                   Ind_Slope  = ifelse(group == "asd", 
                            rep(rlnorm(n, meanlog = asd_change, sdlog = asd_change_var),each=6),
                            rep(rlnorm(n, meanlog = td_change, sdlog = td_change_var),each=6)),
                   MLU_no_error = Ind_Int+(Ind_Slope*(visit-1)),
                   ror = rnorm(12*n,0,error),
                   MLUr =  MLU_no_error + ror,
                   MLU = ifelse(MLUr < 0,0.001,MLUr)                    
                   )
 
}

```

```{r}
#making a nested dataframe with the models

# how many simulations would you like?
n_sim <- 100

# this will help us track time
t1 <- Sys.time()

# here's the main event!
s <-
  tibble(seed = 1:n_sim) %>% 
  mutate(simdata = map(seed, sim_data, n = 30)) %>% 
  mutate(mlu_m1 = map2(simdata, seed, ~update(mlu_m1, newdata = .x, seed = .y)))

t2 <- Sys.time()
```


```{r}
t2-t1
```
```{r}
head(s)
```
```{r}
#map an appropriate function to the nested dataframe and extraxt data
parameters <-
  s %>% 
  mutate(asdslope = map(mlu_m1, ~ fixef(.) %>% 
                           data.frame() %>% 
                           rownames_to_column("parameter"))
         ) %>% 
  unnest(asdslope)

#create a visualizeable dataset
parafull <- merge(
  
  parameters %>% 
  select(-simdata, -mlu_m1) %>% 
  filter(parameter == "groupasd"),
  
  parameters %>% 
  select(-simdata, -mlu_m1) %>% 
  filter(parameter == "grouptd"),
  
  by = "seed"
)

#I saved previous 80 participant simulation data
parafull <- read_csv("parafull.csv")
head(parafull)
```

```{r}
lab_colors <- c("TD" = "blue", "ASD" = "red")
#we need this to have nice colors :)
#now we can take a look at the 95% credibility intervals
parafull<-parafull %>% 

  #we summarize based on the variables we need to insert into the ggplot geom_pointrange
  mutate( power = ifelse( Q2.5.y - Q97.5.x > 0,1,0)) 
# we calculate powwer

parafull %>% 
  ggplot(aes(x=seed)) +
  geom_pointrange(fatten = 1/2,aes(y = Estimate.x ,ymin = Q2.5.x, ymax = Q97.5.x, color = "ASD"))+
  geom_pointrange(fatten = 1/2,aes(y = Estimate.y,ymin = Q2.5.y, ymax = Q97.5.y, color = "TD"))+
  #geom_pointrange is specified
  labs(x = "seed (i.e., simulation index)",
       y = " ",
       color = "Legend",
       #additional labs
       subtitle = str_glue("80 participants from each group, power = {mean(parafull$power)}"))+
  scale_color_manual(values = lab_colors)
 
 
```
## with draws_as_df instead of fixef
```{r}
paradraws_as_df <- s %>% 
  #s is a nested datafreame with a 100 rows of simulations and fitted models
 mutate(`betas` = map(mlu_m1, ~ as_draws_df(.) %>% 
  #we add a new column to that nested dataframe called betas, which takes the models
    #and extracts all posterior values
                          data.frame()%>% 
    #we make betas into a dataframe, so now in the nested dataframe s, we
    #have a 1,seed 2,a simuated set 3,a fitte model 4, a dataframe containing 2000 posteriors for
    #a bunch of betas.
                         rownames_to_column("parameters")))%>%
  #I'm not sure what this does, but it works so I won't touch it
  select(-simdata,-mlu_m1) %>% 
  #We don't want the simulated set or the fitted models, because it would take forever to load.
  unnest(`betas`) %>%
  #we extract the betas
  select(seed,`b_groupasd.visit`,`b_grouptd.visit`)
#we choose the betas we need.
#now we should have a dataframe of 200.000 x 3 , because we have 2000 posteriors for each of the hundred seeds
```

```{r}
lab_colors <- c("TD" = "blue", "ASD" = "red")
#we need this to have nice colors :)
#now we can take a look at all posterior values, not just the 95%,
paradraws_as_df<-paradraws_as_df %>% 
  group_by(seed) %>% 
  #we group the 2000 values by seed
  summarise(mean(b_groupasd.visit),
            min(b_groupasd.visit),
            max(b_groupasd.visit),
            mean(b_grouptd.visit),
            min(b_grouptd.visit),
            max(b_grouptd.visit)) %>% 
  #we summarize based on the variables we need to insert into the ggplot geom_pointrange
  mutate( power = ifelse( `min(b_grouptd.visit)`- `max(b_groupasd.visit)` > 0,1,0)) 
# we calculate powwer

paradraws_as_df %>% 
  ggplot(aes(x=seed)) +
  geom_pointrange(fatten = 1/2,aes(y = `mean(b_groupasd.visit)`,ymin = `min(b_groupasd.visit)`, ymax = `max(b_groupasd.visit)`, color = "ASD"))+
  geom_pointrange(fatten = 1/2,aes(y = `mean(b_grouptd.visit)`,ymin = `min(b_grouptd.visit)`, ymax = `max(b_grouptd.visit)`, color = "TD"))+
  #geom_pointrange is specified
  labs(x = "seed (i.e., simulation index)",
       y = " ",
       color = "Legend",
       #additional labs
       subtitle = str_glue("30 participants from each group, power = {mean(paradraws_as_df$power)}"))+
  scale_color_manual(values = lab_colors)
 
 
```
## 80 % credibility intervals
```{r}
 para_80 <- s %>% 
 mutate(`betas` = map(mlu_m1, ~ posterior_interval(.,prob = .8) %>% 
  
   data.frame()%>% 
                         rownames_to_column("parameters")))%>%
 
  select(-simdata,-mlu_m1) %>% 
  
  unnest(`betas`) %>%
  filter(parameters == "b_groupasd:visit" | parameters == "b_grouptd:visit" )
  
 
para_80 <-merge(
  para_80 %>% 
  filter(parameters == "b_groupasd:visit"),
  para_80 %>% 
  filter(parameters == "b_grouptd:visit"),
  by = "seed")
```

```{r}
para_80<-para_80 %>% 
  mutate( power = ifelse( `X10..y` - `X90..x` > 0,1,0)) 
para_80 %>% 
  ggplot(aes(x=seed)) +
  geom_errorbar(aes( ymin = `X10..x`, ymax = `X90..x`, color = "ASD"))+
  geom_errorbar(aes( ymin = `X10..y`, ymax = `X90..y`, color = "TD"))+
  labs(x = "seed (i.e., simulation index)",
       y = " ",
       color = "Legend",
       subtitle = str_glue("30 participants from each group, power = {mean(para_80$power)}"))+
  scale_color_manual(values = lab_colors)
 
 
```
```{r}
write.csv(para_80,"para_80.csv")
```





# Part 2 - Strong in the Bayesian ken, you are now ready to analyse the actual data

- Describe your sample (n, age, gender, clinical and cognitive features of the two groups) and critically assess whether the groups (ASD and TD) are balanced. Briefly discuss whether the data is enough given the simulations in part 1.
- Describe linguistic development (in terms of MLU over time) in TD and ASD children (as a function of group). Discuss the difference (if any) between the two groups.
- Describe individual differences in linguistic development: do all kids follow the same path? Are all kids reflected by the general trend for their group?

- Include additional predictors in your model of language development (N.B. not other indexes of child language: types and tokens, that'd be cheating). Identify the best model, by conceptual reasoning, model comparison or a mix. Report the model you choose (and name its competitors, if any) and discuss why it's the best model.

```{r}
Realdata <- read_csv("comb_data.csv")
```
## Model 1 CHI_MLU ~ 0+Diagnosis+Diagnosis:VISIT+(1+VISIT|SUBJ)
```{r}
set.seed(3)
#model
mlu_realdata_f <- bf(CHI_MLU ~ 0+Diagnosis+Diagnosis:VISIT+(1+VISIT|SUBJ))
#priors

mlu_realdata_p <- c(
  prior(lognormal(-0.56,0.42), class = b),
  prior(lognormal(0.386,0.4), class = b, coef = "DiagnosisA"),
  prior(lognormal(0.386,0.4), class = b, coef = "DiagnosisB"),
  prior(lognormal(0,0.6), class = sd, coef = Intercept, group= SUBJ),
   prior(lognormal(0,1), class = sd, coef = VISIT, group= SUBJ)
)

#prior predictive check

mlu_realdata_pp1 <- brm(
  mlu_realdata_f,
  data= Realdata,
  prior = mlu_realdata_p,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))
pp_check(mlu_realdata_pp1,ndraws = 100)

#fit
mlu_realdata_m1 <- brm(
  mlu_realdata_f,
  data= Realdata,
  prior = mlu_realdata_p,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))

#prior-posterior update check
pp_check(mlu_realdata_m1,ndraws = 100)
#prior-posterior update plots
post_mlu_realdata_m1 <- as_draws_df(mlu_realdata_m1)

grid.arrange(
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_DiagnosisA), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagnosisA), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept for asd') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_DiagnosisB), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagnosisB), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Inercept for td') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(`prior_b_DiagnosisA:VISIT`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_DiagnosisA:VISIT`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('asd change by visit') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(`prior_b_DiagnosisB:VISIT`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_DiagnosisB:VISIT`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('td change by visit') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_sd_SUBJ__Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_SUBJ__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individual intercepts') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_sd_SUBJ__VISIT), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_SUBJ__VISIT), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individial slopes') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_cor_SUBJ), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(cor_SUBJ__Intercept__VISIT), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('correlation') +
  theme_classic()
)
#summary
summary(mlu_realdata_m1)
#hypothesis testing
hypothesis(mlu_realdata_m1, "DiagnosisA:VISIT < DiagnosisB:VISIT ")
```
```{r}
#visualize estimate, and evaluate their significance
mlu_realdata_m1 %>% 
  fixef() %>% #takes estimates from model
  as.data.frame() %>% #datarames the matrix
  rownames_to_column("Betas") %>% #makes the first column a data frame column
  ggplot(aes(x=Betas))+
         geom_pointrange(fatten = 1/2,aes(y = Estimate, ymin =Q2.5,ymax = Q97.5))+
  geom_abline(intercept = 0,slope = 0)+
  theme_classic()
```

## Model 2 CHI_MLU ~ 0+Diagnosis+Diagnosis:VISIT+(1+VISIT|SUBJ)
```{r}
#normalizing additional predictors
Realdata <- Realdata %>% mutate_at(c("ADOS",
                                     "MullenRaw",
                                     "ExpressiveLangRaw",
                                     "Socialization",
                                     "MOT_MLU",
                                     "types_MOT",
                                     "tokens_MOT"), ~(scale(.) %>% as.vector))
```

```{r}
set.seed(3)
#model
mlu_realdata_f_ados <- bf(CHI_MLU ~ 0+Diagnosis+Diagnosis:VISIT+ADOS+(1+VISIT|SUBJ))
#priors

mlu_realdata_p_ados <- c(
  prior(lognormal(-0.56,0.42), class = b),
  prior(lognormal(0.386,0.4), class = b, coef = "DiagnosisA"),
  prior(lognormal(0.386,0.4), class = b, coef = "DiagnosisB"),
  prior(lognormal(0,0.6), class = sd, coef = Intercept, group= SUBJ),
   prior(lognormal(0,1), class = sd, coef = VISIT, group= SUBJ),
         prior(normal(0,1),class = b, coef = ADOS)
               
)

#prior predictive check

mlu_realdata_pp1_ados <- brm(
  mlu_realdata_f_ados,
  data= Realdata,
  prior = mlu_realdata_p_ados,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))
pp_check(mlu_realdata_pp1_ados,ndraws = 100)

#fit
mlu_realdata_m_ados <- brm(
  mlu_realdata_f_ados,
  data= Realdata,
  prior = mlu_realdata_p_ados,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))

#prior-posterior update check
pp_check(mlu_realdata_m_ados,ndraws = 100)
#prior-posterior update plots
post_mlu_realdata_m1 <- as_draws_df(mlu_realdata_m_ados)

grid.arrange(
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_DiagnosisA), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagnosisA), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept for asd') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_DiagnosisB), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagnosisB), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Inercept for td') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(`prior_b_DiagnosisA:VISIT`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_DiagnosisA:VISIT`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('asd change by visit') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(`prior_b_DiagnosisB:VISIT`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_DiagnosisB:VISIT`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('td change by visit') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_sd_SUBJ__Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_SUBJ__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individual intercepts') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_sd_SUBJ__VISIT), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_SUBJ__VISIT), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individial slopes') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_cor_SUBJ), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(cor_SUBJ__Intercept__VISIT), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('correlation') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_ADOS), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_ADOS), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('ADOS') +
  theme_classic()
)
#summary
summary(mlu_realdata_m_ados)
#hypothesis testing
hypothesis(mlu_realdata_m_ados, "DiagnosisA:VISIT < DiagnosisB:VISIT ")
```
```{r}
#visualize estimate, and evaluate their significance
mlu_realdata_m_ados %>% 
  fixef() %>% #takes estimates from model
  as.data.frame() %>% #datarames the matrix
  rownames_to_column("Betas") %>% #makes the first column a data frame column
  ggplot(aes(x=Betas))+
         geom_pointrange(fatten = 1/2,aes(y = Estimate, ymin =Q2.5,ymax = Q97.5))+
  geom_abline(intercept = 0,slope = 0)+
  theme_classic()
```
## Model 3 CHI_MLU ~ 0+Diagnosis+Diagnosis:VISIT+MullenRaw+ExpressiveLangRaw+Socialization+(1+VISIT|SUBJ)
```{r}
set.seed(3)
#model
mlu_realdata_f_clinic <- bf(CHI_MLU ~ 0+Diagnosis+Diagnosis:VISIT+
                            MullenRaw+
                            ExpressiveLangRaw+
                            Socialization+
                            (1+VISIT|SUBJ))
#priors

mlu_realdata_p_clinic <- c(
  prior(lognormal(-0.56,0.42), class = b),
  prior(lognormal(0.386,0.4), class = b, coef = "DiagnosisA"),
  prior(lognormal(0.386,0.4), class = b, coef = "DiagnosisB"),
  prior(lognormal(0,0.6), class = sd, coef = Intercept, group= SUBJ),
   prior(lognormal(0,1), class = sd, coef = VISIT, group= SUBJ),
         prior(normal(0,1),class = b, coef = MullenRaw),
   prior(normal(0,1),class = b, coef = ExpressiveLangRaw),
   prior(normal(0,1),class = b, coef = Socialization)
               
)

#prior predictive check

mlu_realdata_pp1_clinic <- brm(
  mlu_realdata_f_clinic,
  data= Realdata,
  prior = mlu_realdata_p_clinic,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))
pp_check(mlu_realdata_pp1_clinic,ndraws = 100)

#fit
mlu_realdata_m_clinic <- brm(
  mlu_realdata_f_clinic,
  data= Realdata,
  prior = mlu_realdata_p_clinic,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))

#prior-posterior update check
pp_check(mlu_realdata_m_clinic,ndraws = 100)
#prior-posterior update plots
post_mlu_realdata_m1 <- as_draws_df(mlu_realdata_m_clinic)

grid.arrange(
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_DiagnosisA), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagnosisA), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept for asd') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_DiagnosisB), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagnosisB), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Inercept for td') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(`prior_b_DiagnosisA:VISIT`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_DiagnosisA:VISIT`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('asd change by visit') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(`prior_b_DiagnosisB:VISIT`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_DiagnosisB:VISIT`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('td change by visit') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_sd_SUBJ__Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_SUBJ__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individual intercepts') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_sd_SUBJ__VISIT), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_SUBJ__VISIT), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individial slopes') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_cor_SUBJ), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(cor_SUBJ__Intercept__VISIT), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('correlation') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_MullenRaw), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_MullenRaw), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('MullenRaw') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_ExpressiveLangRaw), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_ExpressiveLangRaw), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('ExpressiveLangRaw') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_Socialization), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_Socialization), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Socialization') +
  theme_classic()
)
#summary
summary(mlu_realdata_m_clinic)
#hypothesis testing
hypothesis(mlu_realdata_m_clinic, "DiagnosisA:VISIT < DiagnosisB:VISIT ")
```
```{r}
#visualize estimate, and evaluate their significance
mlu_realdata_m_clinic %>% 
  fixef() %>% #takes estimates from model
  as.data.frame() %>% #datarames the matrix
  rownames_to_column("Betas") %>% #makes the first column a data frame column
  ggplot(aes(x=Betas))+
         geom_pointrange(fatten = 1/2,aes(y = Estimate, ymin =Q2.5,ymax = Q97.5))+
  geom_abline(intercept = 0,slope = 0)+
  theme_classic()
```
# Bayesian correlation test
Since only ADOS and ExpressiveLangraw seem viable predictors, I need to see to what extent are they correlated.

```{r}
Realdata %>% 
  ggplot(aes(x=ADOS,y = ExpressiveLangRaw,color = Diagnosis))+
  geom_point()+
  geom_smooth(method = glm)
```
It seems in the autistic group, there is a negative correlation. let's test it with bayesian methods.
```{r}
#separate dataframes
RealdataA <- Realdata %>% 
  filter(Diagnosis == "A")
RealdataB <- Realdata %>% 
  filter(Diagnosis == "B")

```
Test correlations for the Typically developing group
```{r}
# specify formula

 B_cortest_f <- bf(mvbind(ADOS, ExpressiveLangRaw) ~ 1) + set_rescor(TRUE)
# priors
 B_cortest_p <- c(prior(gamma(2, .1), class = nu),
                prior(normal(0, 1), class = Intercept, resp = ADOS),
                prior(normal(0, 1), class = Intercept, resp = ExpressiveLangRaw),
                prior(normal(1, .3), class = sigma, resp = ADOS),
                prior(normal(1, .3), class = sigma, resp = ExpressiveLangRaw),
                prior(lkj(1), class = rescor)
                      )
 
 #get_prior(B_cortest_f,RealdataB)
 
# fit
 
  B_cor_mB <- 
  brm(
    B_cortest_f,
    data = RealdataB, 
      family = student,
      prior = B_cortest_p,
      sample_prior = T,
    backend = "cmdstanr",
      iter = 2000, warmup = 500, chains = 2, cores = 4, 
      seed = 210191,
    control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))

```
```{r}
print(B_cor_mB)
```
Test correlations for the Autistic group
```{r}

# fit
 
  B_cor_mA <- update(
    B_cor_mB,
    newdata = RealdataA,
    sample_prior = T,
    backend = "cmdstanr",
      iter = 2000, warmup = 500, chains = 2, cores = 4, 
      seed = 210191,
    control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))

```
```{r}
print(B_cor_mA)
```
## Finalizing models
so, based on the previous section I think the use of these 3 models would be approriate.
Model 1
Model 2
Model 3 -with only ExpressivelangRaw as predictor.
```{r}
#making the the modified model 3
set.seed(3)
#model
mlu_realdata_f_ELR<- bf(CHI_MLU ~ 0+Diagnosis+Diagnosis:VISIT+ExpressiveLangRaw+(1+VISIT|SUBJ))
#priors

mlu_realdata_p_ELR <- c(
  prior(lognormal(-0.56,0.42), class = b),
  prior(lognormal(0.386,0.4), class = b, coef = "DiagnosisA"),
  prior(lognormal(0.386,0.4), class = b, coef = "DiagnosisB"),
  prior(lognormal(0,0.6), class = sd, coef = Intercept, group= SUBJ),
   prior(lognormal(0,1), class = sd, coef = VISIT, group= SUBJ),
         prior(normal(0,1),class = b, coef = ExpressiveLangRaw)
               
)

#prior predictive check

mlu_realdata_pp1_ELR <- brm(
  mlu_realdata_f_ELR,
  data= Realdata,
  prior = mlu_realdata_p_ELR,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))
pp_check(mlu_realdata_pp1_ELR,ndraws = 100)

#fit
mlu_realdata_m_ELR <- brm(
  mlu_realdata_f_ELR,
  data= Realdata,
  prior = mlu_realdata_p_ELR,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))

#prior-posterior update check
pp_check(mlu_realdata_m_ELR,ndraws = 100)
#prior-posterior update plots
post_mlu_realdata_m1 <- as_draws_df(mlu_realdata_m_ELR)

grid.arrange(
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_DiagnosisA), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagnosisA), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept for asd') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_DiagnosisB), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagnosisB), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Inercept for td') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(`prior_b_DiagnosisA:VISIT`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_DiagnosisA:VISIT`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('asd change by visit') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(`prior_b_DiagnosisB:VISIT`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_DiagnosisB:VISIT`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('td change by visit') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_sd_SUBJ__Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_SUBJ__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individual intercepts') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_sd_SUBJ__VISIT), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_SUBJ__VISIT), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('individial slopes') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_cor_SUBJ), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(cor_SUBJ__Intercept__VISIT), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('correlation') +
  theme_classic(),

ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b_ExpressiveLangRaw), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_ExpressiveLangRaw), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('ELR') +
  theme_classic()
)
#summary
summary(mlu_realdata_m_ELR)
#hypothesis testing
hypothesis(mlu_realdata_m_ELR, "DiagnosisA:VISIT < DiagnosisB:VISIT ")
```



Part 3 - From explanation to prediction

## model comparisons 

```{r}
# a function for cleaning data
cleanthat <- function(demodata,ludata,tokendata){
  
  pacman::p_load(tidyverse)
  #1.rename child and visit in demo
  
  demodata <- demodata %>% 
  rename( SUBJ = Child.ID) %>% 
  rename(VISIT = Visit)
  
  #2. uniformize visit
  
  ludata$VISIT <-  ludata$VISIT %>% 
  substr(1,nchar(ludata$VISIT[1])-1) %>% 
  substr(6,nchar(ludata$VISIT[1])) %>% 
  as.integer()
 

  tokendata$VISIT <-  tokendata$VISIT %>% 
  substr(1,nchar(tokendata$VISIT[1])-1) %>% 
  substr(6,nchar(tokendata$VISIT[1])) %>% 
  as.integer()
  
  #3. remove dots
  
  demodata$SUBJ <- gsub("\\.","",demodata$SUBJ)
  ludata$SUBJ <- gsub("\\.","",ludata$SUBJ)
  tokendata$SUBJ <- gsub("\\.","",tokendata$SUBJ)

  demodata$ID <- paste(demodata$SUBJ,demodata$VISIT, sep= "_")
  ludata$ID <- paste(ludata$SUBJ,ludata$VISIT, sep= "_")
  tokendata$ID <- paste(tokendata$SUBJ,tokendata$VISIT, sep= "_")
  
  #4. merge sets
  
  df_big <- merge(merge(demodata, ludata, by = "ID", all = TRUE),tokendata, by = "ID", all = TRUE) %>% select(ID,
SUBJ, 
VISIT, 
Diagnosis, 
Ethnicity, 
Gender, 
Age, 
ADOS,  
MullenRaw, 
ExpressiveLangRaw, 
Socialization,
MOT_MLU, 
CHI_MLU, 
types_MOT, 
types_CHI, 
tokens_MOT, 
tokens_CHI)

  #5. fix names (while merging some SUBJ and VISIT values turned to Nas)
  
for (x in df_big$SUBJ) {

if(is.na(x)){
  
  df_big$SUBJ <- df_big$ID %>% 
   substr(1,nchar(df_big$ID)-2)
  
  
}
}

for (x in df_big$VISIT) {

if(is.na(x)){
  
  df_big$VISIT <- df_big$ID %>% 
   substr(nchar(df_big$ID),nchar(df_big$ID)) %>% 
  as.integer()
  
}
}
  # 6. put only visit one values in clinical variables
  
  x <- 1
while (x<length(df_big$VISIT)+1){

if (df_big$VISIT[x] == 1) { 
  
  y <- df_big$ADOS[x]
  y_1 <- df_big$MullenRaw[x]
  y_2 <- df_big$ExpressiveLangRaw[x]
  y_3 <- df_big$Socialization[x]
  
  
 
} 
  df_big$MullenRaw[x] <- y_1
  df_big$ExpressiveLangRaw[x] <- y_2
  df_big$Socialization[x] <-y_3
   df_big$ADOS[x] <- y
   x <- x+1
   
  }

    #7. change 1  and 2 to male and female
  df_big <- df_big %>% 
  mutate(Gender = ifelse(Gender == 1,"MALE","FEMALE"))
  
  #8. Anonymize children SUBJ values
  x_2 <- 1
while (x_2<length(df_big$VISIT)+1){

if (df_big$VISIT[x_2] == 1) { 
  
  y_4 <- x_2
 
  
 
} 
  df_big$SUBJ[x_2] <- y_4
   x_2 <- x_2+1
   
}
  
  # 10. reassing IDS
  df_big$ID <- paste(df_big$SUBJ,df_big$VISIT, sep= "_")
  
  return(df_big)
}

```

```{r}
#creating predictions from the training set
Realdata_pred <- Realdata %>% 
  mutate( Predm1 = predict(mlu_realdata_m1, newdata = Realdata, allow_new_levels = T),
          Predmados = predict(mlu_realdata_m_ados, newdata = Realdata, allow_new_levels = T),
          Predmelr = predict(mlu_realdata_m_ELR, newdata = Realdata, allow_new_levels = T )) %>% 
  drop_na(CHI_MLU)

```

```{r}
#importing new data

test_Realdata <- cleanthat(read_csv("demo_test.csv"),
                           read_csv("LU_test.csv"),
                           read_csv("token_test.csv"))

#fixing a bug with age
test_Realdata<- test_Realdata %>% 
  mutate(Age = ifelse(Age > 999,Age/100,Age/10))
test_Realdata[20,7] <- 23.0

#standardizing variables with tidymodels. The scale of the model should be used on the test set, since standardizing the data makes it specific to the data set.
#we need the unstandardized real data, and I don't want to reload everything again
Realdata_2 <- read_csv("comb_data.csv")

rec_stan <- Realdata_2 %>% 
  recipe(CHI_MLU ~ .) %>% 
  step_scale(ADOS, MullenRaw, ExpressiveLangRaw, Socialization) %>% 
  step_center(ADOS, MullenRaw, ExpressiveLangRaw, Socialization) %>% 
  prep(training = Realdata_2, retain = T)

Realdata_2 <- bake(rec_stan, Realdata_2)
test_Realdata_s <- bake(rec_stan, new_data = test_Realdata)
#individual ids were lost and I like those
test_Realdata_s$ID <- test_Realdata$ID


```

```{r}
set.seed(3)
#creating predictions from the test set
test_Realdata <- test_Realdata_s %>% 
  mutate( Predm1 = predict(mlu_realdata_m1, newdata = test_Realdata_s, allow_new_levels = T),
          Predmados = predict(mlu_realdata_m_ados, newdata = test_Realdata_s, allow_new_levels = T),
          Predmelr = predict(mlu_realdata_m_ELR, newdata = test_Realdata_s, allow_new_levels = T )) %>% 
  drop_na(CHI_MLU) # removing a visit without measure MLU, since we have no comaprison

#cross validation
kfoldm1 <- kfold(mlu_realdata_m1, folds = "stratified", group = "SUBJ", K= 5, save_fits = T)
kfpm1 <- kfold_predict(kfoldm1)

kfoldm_ados <- kfold(mlu_realdata_m_ados, folds = "stratified", group = "SUBJ", K= 5, save_fits = T)
kfpm_ados <- kfold_predict(kfoldm_ados)

kfoldm_elr <- kfold(mlu_realdata_m_ELR, folds = "stratified", group = "SUBJ", K= 5, save_fits = T)
kfpm_elr <- kfold_predict(kfoldm_elr)

# tibble it
rmse_compare <- tibble( model = rep(c("Baseline","ADOS","ELR"),3),
                        type = c(rep("RMSE",3),rep("RMSE_test",3),rep("RMSE_CV",3)),
                        value = c(
                          #rmse with train data
sqrt(mean((Realdata_pred$CHI_MLU - Realdata_pred$Predm1[1,])^2)),
sqrt(mean((Realdata_pred$CHI_MLU - Realdata_pred$Predmados[1,])^2)),
sqrt(mean((Realdata_pred$CHI_MLU - Realdata_pred$Predmelr[1,])^2)),
# rmse with test data
sqrt(mean((test_Realdata$CHI_MLU - test_Realdata$Predm1[1,])^2)),
sqrt(mean((test_Realdata$CHI_MLU - test_Realdata$Predmados[1,])^2)),
sqrt(mean((test_Realdata$CHI_MLU - test_Realdata$Predmelr[1,])^2)),
#rmse with cross validation ( colmeans is for an average for the 2000 posteriors for the values)
sqrt(mean((kfpm1$y - colMeans(kfpm1$yrep))^2)),
sqrt(mean((kfpm_ados$y - colMeans(kfpm_ados$yrep))^2)),
sqrt(mean((kfpm_elr$y - colMeans(kfpm_elr$yrep))^2))
                        )

)


```
```{r}
#plot it
#for a non alphabetical order
level_order <- c('RMSE', 'RMSE_test', 'RMSE_CV')

rmse_compare %>% 
  ggplot(aes(x = factor(type,levels = level_order), y = value, color = model, group = model))+
  geom_point()+
  geom_line()+
  theme_classic()
```
```{r}
set.seed(3)
loo_compare(loo(mlu_realdata_m1),loo(mlu_realdata_m_ados),loo(mlu_realdata_m_ELR))
```


N.B. There are several datasets for this exercise, so pay attention to which one you are using!

1. The (training) dataset from last time (the awesome one you produced :-) ).
2. The (test) datasets on which you can test the models from last time:
* Demographic and clinical data: https://www.dropbox.com/s/ra99bdvm6fzay3g/demo_test.csv?dl=1
* Utterance Length data: https://www.dropbox.com/s/uxtqqzl18nwxowq/LU_test.csv?dl=1
* Word data: https://www.dropbox.com/s/1ces4hv8kh0stov/token_test.csv?dl=1

Relying on the model(s) you trained in part 2 of the exercise, create predictions for the test set and assess how well they do compared to the actual data.

- Discuss the differences in performance of your model in training and testing data. Is the model any good?
- Let's assume you are a speech therapy clinic. You want to assess whether the kids in your test sample will have a typical (like a TD) development, or they will have a worse one, in which case they should get speech therapy support. What do your predictions tell you about that? Which kids would you provide therapy for? Is the model any good?
```{r}
#we need to check children's ages in the test set to figure out at which mue should they get therapy
test_Realdata %>% 
  group_by(SUBJ, VISIT) %>% 
  summarise(Age) %>% 
  filter(VISIT == 6) %>% 
  ggplot(aes(x = as.factor(SUBJ), y = Age))+
  geom_point()

```

```{r}
set.seed(3)
#Predicting MLU values from first visit
test_2_Realdata <- test_Realdata %>% 
  mutate( CHI_MLU = ifelse(VISIT > 1,NaN,CHI_MLU))

test_2_Realdata <- test_2_Realdata %>% 
  mutate( Predm1 = predict(mlu_realdata_m1, newdata = test_2_Realdata, allow_new_levels = T),
          Predmados = predict(mlu_realdata_m_ados, newdata = test_2_Realdata, allow_new_levels = T),
          Predmelr = predict(mlu_realdata_m_ELR, newdata = test_2_Realdata, allow_new_levels = T ))
```


```{r}
#by visit 6, most kids are older than 40 weeks and according to: :https://speechandlanguageathome.com/blog/out-with-the-baby-talk-up-with-the-mlu#:~:text=12%2D26%20months%3A%20average%20MLU,range%20from%203.0%20to%203.75
# 35-40 months: average MLU is 3.5, with a range from 3.0 to 3.75
# 41-46+ months: average MLU is 4.0, with a range from 3.75 to 4.5
# so we need to see from which starting MLU will children reach this.

# help with real values on the plot
testhelp <- 
rbind(
test_Realdata %>% 
  filter(VISIT == 6) %>% 
  select(SUBJ,Diagnosis,CHI_MLU,Predm1) %>% 
  mutate( values = Predm1,
          mod = "Baseline",
          SUBJ_mod = paste(as.character(SUBJ), "b",sep = "_")
          ) %>% 
  select(-Predm1),
test_Realdata %>% 
  filter(VISIT == 6) %>% 
  select(SUBJ,Diagnosis,CHI_MLU,Predmelr) %>% 
  mutate( values = Predmelr,
          mod = "ELR",
          SUBJ_mod = paste(as.character(SUBJ), "elr",sep = "_")
          ) %>% 
   select(-Predmelr),
test_Realdata %>% 
  filter(VISIT == 6) %>% 
  select(SUBJ,Diagnosis,CHI_MLU,Predmados) %>% 
  mutate( values = Predmados,
          mod = "ADOS",
          SUBJ_mod = paste(as.character(SUBJ), "ados",sep = "_")
          ) %>% 
   select(-Predmados)
)
#testdata
# I wrangle the data into ggplot compatibility. I take the 6th visit, +relevant values from models, harmonize names and add a mod column to differentiate. then I bind it vertically.
# to help visualization I factored Ids by model
rbind(
test_2_Realdata %>% 
  filter(VISIT == 6) %>% 
  select(SUBJ,Diagnosis,CHI_MLU,Predm1) %>% 
  mutate( values = Predm1,
          mod = "Baseline",
          SUBJ_mod = paste(as.character(SUBJ), "b",sep = "_")
          ) %>% 
  select(-Predm1),
test_2_Realdata %>% 
  filter(VISIT == 6) %>% 
  select(SUBJ,Diagnosis,CHI_MLU,Predmelr) %>% 
  mutate( values = Predmelr,
          mod = "ELR",
          SUBJ_mod = paste(as.character(SUBJ), "elr",sep = "_")
          ) %>% 
   select(-Predmelr),
test_2_Realdata %>% 
  filter(VISIT == 6) %>% 
  select(SUBJ,Diagnosis,CHI_MLU,Predmados) %>% 
  mutate( values = Predmados,
          mod = "ADOS",
          SUBJ_mod = paste(as.character(SUBJ), "ados",sep = "_")
          ) %>% 
   select(-Predmados)
) %>% 
  #general
  ggplot(aes(y=SUBJ_mod, color = Diagnosis,))+
  #visualizing values
         geom_pointrange(fatten = 1/2,aes(x = values[,1], xmin =values[,3],xmax =values[,4]))+
  geom_errorbar(aes(xmin =values[,3],xmax =values[,4]))+
  #real 6th visit mlus
  geom_point(aes(x=testhelp$CHI_MLU, color = "Real MLU"))+
  #adding the "normal range"
  geom_rect(aes(ymin = 0,
                ymax = Inf,
                  xmin = 3,
                  xmax = 4.5),
              fill = "green",
              alpha = 0.01) +
  geom_vline(xintercept = 3) +
  geom_vline(xintercept = 4.5) +
  #separating children for better plot readability
  geom_abline(intercept = 3.5,slope =0, alpha= 0.5)+
   geom_abline(intercept = 6.5,slope =0, alpha= 0.5)+
   geom_abline(intercept = 9.5,slope =0, alpha= 0.5)+
   geom_abline(intercept = 12.5,slope =0, alpha= 0.5)+
  geom_abline(intercept = 15.5,slope =0, alpha= 0.5)+
  #labels and themes
  theme_classic()+
  ylab("ID and model used")+
  xlab("MLU")+
  ggtitle("Predicted MLU values for children from the test set")


```

After all these comparative and predictive methods, I would choose the model with MLU and ELR values.

## speech clinic roleplay
```{r}
#if I run a speech clinic, I should have at least some tables so that I can evaluate children on the go

#possible first visit values, lets go to 2.5, since if they reach 3, then they don't need therapy
#possible elr values

Realdata_2 %>% 
  drop_na(ExpressiveLangRaw) %>% 
  group_by(VISIT) %>% 
  summarise(max(ExpressiveLangRaw))
# So lets go to 30 first
#simulate combos for elr 0-30 and mlu 0-2.5
# I created the combos for visit 1, copied and bound it for visit two, then copied the whole ting and rbinded it to Diagnosis B
pred_table_values <- 
  rbind(
    rbind(tibble( SUBJ = seq(1,806, by = 1),
          CHI_MLU = rep(seq(0,2.5, by = .1), each = 31),
          ExpressiveLangRaw = rep(0:30, times = 26),
          VISIT = rep(1, times = 806),
          Diagnosis = rep("A",times = 806)),
        tibble( SUBJ = seq(1,806, by = 1),
          CHI_MLU = rep(NA, times = 806),
          ExpressiveLangRaw = rep(0:30, times = 26),
          VISIT = rep(6, times = 806),
          Diagnosis = rep("A",times = 806))
  ), rbind(tibble( SUBJ = seq(1+900,806+900, by = 1),
          CHI_MLU = rep(seq(0,2.5, by = .1), each = 31),
          ExpressiveLangRaw = rep(0:30, times = 26),
          VISIT = rep(1, times = 806),
          Diagnosis = rep("B",times = 806)),
        tibble( SUBJ = seq(1+900,806+900, by = 1),
          CHI_MLU = rep(NA, times = 806),
          ExpressiveLangRaw = rep(0:30, times = 26),
          VISIT = rep(6, times = 806),
          Diagnosis = rep("B",times = 806))
  )
)
set.seed(3)

#adding the standardized values

rec_pred <- Realdata_2 %>% 
  recipe(
         vars = c("CHI_MLU","SUBJ","VISIT","ExpressiveLangRaw","Diagnosis")) %>% 
  step_scale(ExpressiveLangRaw) %>% 
  step_center(ExpressiveLangRaw) %>% 
  prep(training = Realdata_2, retain = T)


pred_table_values_s <- bake(rec_pred, new_data = pred_table_values)

#adding reference og elr
pred_table_values_s$ELR <- pred_table_values$ExpressiveLangRaw

#predict
pred_table_values <- pred_table_values_s %>% 
  mutate(pred = predict(mlu_realdata_m_ELR, newdata = pred_table_values_s, allow_new_levels = T ))

#make it easy to see who needs it
pred_table_values <- pred_table_values %>% 
  mutate(ST = ifelse(pred[,1] < 3,1,0))

```

```{r}

#letssee for Autistic 
#wrangle it 
pred_needs <- merge(
  pred_table_values %>% 
  filter(VISIT == 1) %>% 
  filter(Diagnosis == "A"),
  pred_table_values %>% 
  filter(VISIT == 6) %>% 
  filter(Diagnosis == "A"), by = "SUBJ")

pred_needs <- pred_needs %>% 
  mutate( ST = as.logical(ST.y)) %>% 
  select(CHI_MLU.x,ELR.x,ST)
# move values into a column
pred_table <- pred_needs
# aggregate by Vertical and Horizontal

# re-arrange into the desired form
knitr::kable(spread(pred_table, CHI_MLU.x, ST))

```

```{r}
#table testing
# example data
exd <- data.frame(
    Vertical   = c(10,10,2.5,5,10,5,2.5,10,1.25,1.25,1.25, 1.25),
    Horizontal = c(2,2,3,2,4,2,3,4,1,4,4,1),
    row.names = LETTERS[1:12])

# move values into a column
exd <- mutate(exd,
              Value = rownames(exd))
# aggregate by Vertical and Horizontal
exd <- summarize(group_by(exd, Vertical, Horizontal),
                 Value = paste(Value, collapse = ","))
# re-arrange into the desired form
spread(exd, Horizontal, Value)
```


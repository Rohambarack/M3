---
title: "Untitled"
author: "Balazs Szabo"
date: "2022-11-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
remove.packages("vctrs")
remove.packages(c("Rcpp","dplyr","rlang"))
install.packages(c("Rcpp","dplyr","rlang","vctrs"))
library(tidyverse)
library(brms)
library(gridExtra)
library(cmdstanr)
library(tidymodels)
library(truncnorm)
```
## Part I - Simulating data

Use the meta-analysis reported in Parola et al (2020), create a simulated dataset with 100 matched pairs of schizophrenia and controls, each participant producing 10 repeated measures (10 trials with their speech recorded). for each of these "recordings" (data points) produce 10 acoustic measures: 6 from the meta-analysis, 4 with just random noise. Do the same for a baseline dataset including only 10 noise variables. Tip: see the slides for the code. 

```{r}
#number of participants
n = 100

#effect means
Informed_effect_mean <- c(.25,-.55,-.75,-1.26,.05,1.89,0,0,0,0)
Skeptic_effect_mean <- rep(0,10)

#individual sds
Individual_sd <- 1
Trial_sd <- .5
Error <- .2
  
  
#simulate it 
inf_simdata <-
  tibble(
    ID = rep(rep(seq(1,n), each = 10),2),
    Diagnosis = rep(c("Schizophrenia","Control"), each = n*10),
    Trial = rep(seq(1,10), n*2)
  )


#figuring out a solution
 teszt <- tibble(
    ID = rep(rep(seq(1,n), each = 10),2),
    Diagnosis = rep(c("Schizophrenia","Control"), each = n*10),
    Trial = rep(seq(1,10), n*2)
  )
  #  the mapply function applies the rnorm to get one value, 100 times, eith the means of 3 different groups a 100 times. so it will return 100 random values for the 3 different means, but since we need 10 to be the same, because it is the "true" value for the participants, we rep each 10 times.
  teszt2 <- rep(mapply(rnorm, n = rep(1,100), mean = rep(c(0,100,1000), each = 100), sd = Individual_sd), each = 10)
  
  #the 3000 element vector then gets turned into a matrix with 3 1000 long columns
  teszt3 <- as.data.frame(matrix(teszt2,ncol =3,byrow = F))
  #because the true effect is the same for the two parts of the control group, we bind it with itself
  teszt4 <- rbind(teszt3,teszt3)
# we add the columns to the existing dataframe
teszt <- teszt %>% 
     tibble::add_column(!!!set_names(teszt4,
                                     nm=c("vt1","vt2","vt3")))



```

```{r}
set.seed(3)
#continue the simulation

#  the mapply function applies the rnorm to get one value, 100 times, eith the means of 3 different groups a 100 times. so it will return 100 random values for the 10 different means, but since we need 10 to be the same, because it is the "true" value for the participants, we rep each 10 times.
  inf_help1 <- rep(mapply(rnorm, n = rep(1,100), mean = rep(Informed_effect_mean, each = 100), sd = Individual_sd), each = 10)
  
  #the 3000 element vector then gets turned into a matrix with 10,  1000 long columns
  inf_help2 <- as.data.frame(matrix(inf_help1,ncol =10,byrow = F))
  #because the true effect is the same for the two parts of the control group, we bind it with itself
  inf_help3 <- rbind(inf_help2,inf_help2)
# we add the columns to the existing dataframe
inf_simdata <- inf_simdata %>% 
     tibble::add_column(!!!set_names(inf_help3,
                                     nm=c("vt1","vt2","vt3","vt4","vt5",
                                          "vt6","vt7","vt8","vt9","vt10")))


```


```{r}
#now lets figure out how to make the test differences
set.seed(3)
for (i in seq(nrow(teszt))){
  
  teszt$v1[i] <- ifelse(teszt$Diagnosis[i] == "Schizophrenia",
                    rnorm(1,rnorm(1,teszt$vt1[i]/2,Trial_sd),Error),
                    rnorm(1,rnorm(1,(-teszt$vt1[i])/2,Trial_sd),Error))
  
}


teszt <- teszt %>% 
  rowwise() %>% 
  mutate( v1_s = ifelse(Diagnosis == "Schizophrenia",
                    rnorm(1,rnorm(1,vt1/2,Trial_sd),Error),
                    rnorm(1,rnorm(1,(-vt1)/2,Trial_sd),Error)))


teszt_fax <- teszt %>% 
  rowwise() %>% 
  mutate(across( .cols =  starts_with("vt"), ~ ifelse(Diagnosis == "Schizophrenia",
                    rnorm(1,rnorm(1,./2,Trial_sd),Error),
                    rnorm(1,rnorm(1,(-.)/2,Trial_sd),Error)),
         ))
```

```{r}

simulate_sci <- function(n,Informed_effect_mean,Individual_sd,Trial_sd){
  set.seed(3)
  
  #simulate it 
inf_simdata <-
  tibble(
    ID = rep(rep(seq(1,n), each = 10),2),
    Diagnosis = rep(c("Schizophrenia","Control"), each = n*10),
    Trial = rep(seq(1,10), n*2)
  )

  #  the mapply function applies the rnorm to get one value, 100 times, eith the means of 3 different groups a 100 times. so it will return 100 random values for the 10 different means, but since we need 10 to be the same, because it is the "true" value for the participants, we rep each 10 times.
  inf_help1 <- rep(mapply(rnorm, n = rep(1,100), mean = rep(Informed_effect_mean, each = 100), sd = Individual_sd), each = 10)
  
  #the 3000 element vector then gets turned into a matrix with 10,  1000 long columns
  inf_help2 <- as.data.frame(matrix(inf_help1,ncol =10,byrow = F))
  #because the true effect is the same for the two parts of the control group, we bind it with itself
  inf_help3 <- rbind(inf_help2,inf_help2)
# we add the columns to the existing dataframe
inf_simdata <- inf_simdata %>% 
     tibble::add_column(!!!set_names(inf_help3,
                                     nm=c("vt1","vt2","vt3","vt4","vt5",
                                          "vt6","vt7","vt8","vt9","vt10")))

inf_simdata <- inf_simdata %>% 
  rowwise() %>% 
  mutate(across( .cols =  starts_with("vt"), ~ ifelse(Diagnosis == "Schizophrenia",
                    rnorm(1,rnorm(1,./2,Trial_sd),Error),
                    rnorm(1,rnorm(1,(-.)/2,Trial_sd),Error)),
         ))
  
return(inf_simdata)
  
}

```

```{r}

inf_simdata <- simulate_sci(100,Informed_effect_mean,Individual_sd,Trial_sd)
skep_simdata <- simulate_sci(100,Skeptic_effect_mean,Individual_sd,Trial_sd)
```

```{r}
#visualize it

#wrangle it first
teszt_fax_2 <- teszt_fax[,1:4] %>% 
  mutate( Predictor = "v1") %>% 
  rename(Value = "vt1")

#so 



for (i in seq(ncol(inf_simdata)-3)){
  
  temp_inf <- inf_simdata[,c(1:3,(i+3))] %>% 
  mutate( Predictor = as.character(colnames(inf_simdata[(i+3)]))
          ) %>% 
  rename(Value = colnames(inf_simdata[(i+3)])
           )
  if (i == 1){
    
    inf_vis <- temp_inf
    
  }else{
    inf_vis <- rbind(inf_vis,temp_inf)
  }
  
}


for (i in seq(ncol(skep_simdata)-3)){
  
  temp_skep <- skep_simdata[,c(1:3,(i+3))] %>% 
  mutate( Predictor = as.character(colnames(skep_simdata[(i+3)]))
          ) %>% 
  rename(Value = colnames(skep_simdata[(i+3)])
           )
  if (i == 1){
    
    skep_vis <- temp_skep
    
  }else{
    skep_vis <- rbind(skep_vis,temp_skep)
  }
  
}
```
```{r}
#now visualize it

grid.arrange(
  
inf_vis %>% 
  ggplot(aes(x=Value, fill = Diagnosis, group = Diagnosis))+
  geom_density(alpha=.5)+
  scale_fill_manual(values = c("#3cb44b","#dcbeff"))+
  facet_wrap(~Predictor)+
  ylab("")+
  xlab("")+
  ggtitle("Informed")+
  theme(axis.text.y=element_blank(), #remove x axis labels
        axis.ticks.y=element_blank()
        ), #remove x axis ticks,

skep_vis %>% 
  ggplot(aes(x=Value, fill = Diagnosis, group = Diagnosis))+
  geom_density(alpha=.5)+
  scale_fill_manual(values = c("#3cb44b","#dcbeff"))+
  facet_wrap(~Predictor)+
  ylab("")+
  xlab("")+
  ggtitle("Noise")+
  theme(axis.text.y=element_blank(), #remove x axis labels
        axis.ticks.y=element_blank()
        )
)
```

## Part II - ML pipeline on simulated data

On the two simulated datasets (separately) build a machine learning pipeline: i) create a data budget (e.g. balanced training and test sets); ii) pre-process the data (e.g. scaling the features); iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression); iv) assess performance on the test set; v) discuss whether performance is as expected and feature importance is as expected.

Bonus question: replace the bayesian multilevel regression with a different algorithm, e.g. SVM or random forest (but really, anything you'd like to try).

i) I would normally select the test set based on demographic information, but if it should resemble the training set lets see, what we can do.
maybe lets take participants, who are within one standard deviation in all values, so they are not outliers?


```{r}
#remove test set values 
Trial_ID <- sample(seq(n),20)

inf_simdata_test <- inf_simdata %>% 
  subset(ID %in% Trial_ID)

inf_simdata_train <- inf_simdata %>% 
  subset(!ID %in% Trial_ID)

skep_simdata_test <- skep_simdata %>% 
  subset(ID %in% Trial_ID)

skep_simdata_train <- skep_simdata %>% 
  subset(!ID %in% Trial_ID)
```


ii) pre-process the data (e.g. scaling the features);
```{r}
#standardize values

rec_stan_inf <- inf_simdata_train %>% 
  recipe(Diagnosis ~ .) %>% 
  step_scale(vt1,vt2,vt3,vt4,vt5,vt6,vt7,vt8,vt9,vt10) %>% 
  step_center(vt1,vt2,vt3,vt4,vt5,vt6,vt7,vt8,vt9,vt10) %>% 
  prep(training = inf_simdata_train, retain = T)

inf_simdata_train_s <- bake(rec_stan_inf, inf_simdata_train)

```
iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression);

```{r}
set.seed(3)
#model
inf_m_f<- bf(Diagnosis ~ 1 + vt1+vt2+vt3+vt4+vt5+vt6+vt7+vt8+vt9+vt10)
#priors

inf_m_p <- c(
  prior(normal(0,1), class = Intercept),
  prior(normal(1,.3), class = b)
 
               
)

#prior predictive check

inf_m_pp <- brm(
  inf_m_f,
  data= inf_simdata_train_s,
  prior = inf_m_p,
  family = bernoulli,
  sample_prior = "only",
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))
pp_check(inf_m_pp,ndraws = 100)

#fit
inf_m <- brm(
  inf_m_f,
  data= inf_simdata_train_s,
  family = bernoulli,
  prior = inf_m_p,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 5,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  ))


#prior-posterior update check
pp_check(inf_m,ndraws = 100)
#prior-posterior update plots
post_mlu_realdata_m1 <- as_draws_df(inf_m)

grid.arrange(
  ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt1), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt1') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt2), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt2') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt3), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt3') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt4), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt4') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt5), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt5') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt6), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt6') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt7), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt7') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt8), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt8') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt9), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt9') +
  theme_classic(),
ggplot(post_mlu_realdata_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_vt10), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('vt10') +
  theme_classic()

)
#summary
summary(inf_m)
```
```{r}
set.seed(3)
#informed model with individual intercepts
#prior predictive check

inf_m1_f <- bf(Diagnosis ~ 1 + vt1+vt2+vt3+vt4+vt5+vt6+vt7+vt8+vt9+vt10+(1|ID))

inf_m1_pp <- update(inf_m_pp,
                    formula. = inf_m1_f,
                    newdata = inf_simdata_train_s)
pp_check(inf_m1_pp,ndraws = 100)

#fit
inf_m1 <- update(inf_m,
                    formula. = inf_m1_f,
                    newdata = inf_simdata_train_s)

#prior-posterior update check
pp_check(inf_m1,ndraws = 100)
#sum
summary(inf_m1)
```
```{r}
set.seed(3)
#informed model with individual intercepts and slopes.
#prior predictive check

inf_m2_f <- bf(Diagnosis ~ 1 + vt1+vt2+vt3+vt4+vt5+vt6+vt7+vt8+vt9+vt10+
                 (1+vt1+vt2+vt3+vt4+vt5+vt6+vt7+vt8+vt9+vt10|ID))

inf_m2_pp <- update(inf_m_pp,
                    formula. = inf_m2_f,
                    newdata = inf_simdata_train_s)
pp_check(inf_m1_pp,ndraws = 100)

#fit
inf_m2 <- update(inf_m,
                    formula. = inf_m2_f,
                    newdata = inf_simdata_train_s)

#prior-posterior update check
pp_check(inf_m2,ndraws = 100)
#sum
summary(inf_m2)
```
```{r}
#standardize values

rec_stan_skep <- skep_simdata_train %>% 
  recipe(Diagnosis ~ .) %>% 
  step_scale(vt1,vt2,vt3,vt4,vt5,vt6,vt7,vt8,vt9,vt10) %>% 
  step_center(vt1,vt2,vt3,vt4,vt5,vt6,vt7,vt8,vt9,vt10) %>% 
  prep(training = skep_simdata_train, retain = T)

skep_simdata_train_s <- bake(rec_stan_skep, skep_simdata_train)

```

```{r}
set.seed(3)
#skeptic model
#prior predictive check

skep_m_pp <- update(inf_m_pp,
                    newdata = skep_simdata_train_s)
pp_check(skep_m_pp,ndraws = 100)

#fit
skep_m <- update(inf_m,
                    newdata = skep_simdata_train_s)

#prior-posterior update check
pp_check(skep_m,ndraws = 100)
#sum
summary(skep_m)
```

```{r}
set.seed(3)
#skep model with individual intercepts
#prior predictive check

skep_m1_pp <- update(inf_m_pp,
                    formula. = inf_m1_f,
                    newdata = skep_simdata_train_s)
pp_check(skep_m1_pp,ndraws = 100)

#fit
skep_m1 <- update(inf_m,
                    formula. = inf_m1_f,
                    newdata = skep_simdata_train_s)

#prior-posterior update check
pp_check(skep_m1,ndraws = 100)
#sum
summary(skep_m1)
```


```{r}
set.seed(3)
#skep model with individual intercepts and slopes.
#prior predictive check

skep_m2_pp <- update(inf_m_pp,
                    formula. = inf_m2_f,
                    newdata = skep_simdata_train_s)
pp_check(skep_m1_pp,ndraws = 100)

#fit
skep_m2 <- update(inf_m,
                    formula. = inf_m2_f,
                    newdata = skep_simdata_train_s)

#prior-posterior update check
pp_check(skep_m2,ndraws = 100)
#sum
summary(skep_m2)
```

```{r}
#add predictions
set.seed(3)

skep_simdata_pred <- skep_simdata_train_s
skep_simdata_pred$m <- predict(skep_m, newdata = skep_simdata_train_s)
skep_simdata_pred$m1 <- predict(skep_m1, newdata = skep_simdata_train_s)
skep_simdata_pred$m2 <- predict(skep_m2, newdata = skep_simdata_train_s)

inf_simdata_pred <- inf_simdata_train_s
inf_simdata_pred$m <- predict(inf_m, newdata = inf_simdata_train_s)
inf_simdata_pred$m1 <- predict(inf_m1, newdata = inf_simdata_train_s)
inf_simdata_pred$m2 <- predict(inf_m2, newdata = inf_simdata_train_s)

#scale values for test set based on trian scales

inf_simdata_test_s <- bake(rec_stan_inf, inf_simdata_test)
skep_simdata_test_s <- bake(rec_stan_skep, inf_simdata_test)

skep_simdata_pred_test <- skep_simdata_test_s
skep_simdata_pred_test$m <- predict(skep_m, newdata = skep_simdata_test_s, allow_new_levels =T)
skep_simdata_pred_test$m1 <- predict(skep_m1, newdata = skep_simdata_test_s, allow_new_levels =T)
skep_simdata_pred_test$m2 <- predict(skep_m2, newdata = skep_simdata_test_s, allow_new_levels =T)

inf_simdata_pred_test <- inf_simdata_test_s
inf_simdata_pred_test$m <- predict(inf_m, newdata = inf_simdata_test_s, allow_new_levels =T)
inf_simdata_pred_test$m1 <- predict(inf_m1, newdata = inf_simdata_test_s, allow_new_levels =T)
inf_simdata_pred_test$m2 <- predict(inf_m2, newdata = inf_simdata_test_s, allow_new_levels =T)

```

```{r}
#fuck it we are going old R
  
  accuracy_1 <- function(df){
    
    df2 <- df %>% 
      select(ID, Trial, Diagnosis)
    
    df2$m <- df$m[,1]
    df2$m1 <- df$m1[,1]
    df2$m2 <- df$m2[,1]
    
    df2 <- df2 %>% 
mutate(across(.cols = starts_with("m"),  ~ ifelse( .  > 0.5, "Schizophrenia","Control")))
    
    df2<- df2 %>% 
      ungroup() %>% 
      mutate(across(.cols = starts_with("m"), ~ as.factor(.)))
        
    return(df2)
  }

inf_simdata_pred_2 <- accuracy_1(inf_simdata_pred)
inf_simdata_pred_test_2 <- accuracy_1(inf_simdata_pred_test)
skep_simdata_pred_2 <- accuracy_1(skep_simdata_pred)
skep_simdata_pred_test_2 <- accuracy_1(skep_simdata_pred_test)

```

Overall accuracy
```{r}

fscores <- tibble(
  set = rep(c("Informed","Skeptic"),each = 6),
  model = rep(c("Fixed","Var.Intercept","Var.Slope"), 4),
  test = rep(rep(c("Train","Test"),each = 3),2),
  score = c( f_meas(inf_simdata_pred_2,
         truth = Diagnosis,
         estimate = m)[1,3],
         f_meas(inf_simdata_pred_2,
         truth = Diagnosis,
         estimate = m1)[1,3],
         f_meas(inf_simdata_pred_2,
         truth = Diagnosis,
         estimate = m2)[1,3],
         
         f_meas(inf_simdata_pred_test_2,
         truth = Diagnosis,
         estimate = m)[1,3],
          f_meas(inf_simdata_pred_test_2,
         truth = Diagnosis,
         estimate = m1)[1,3],
          f_meas(inf_simdata_pred_test_2,
         truth = Diagnosis,
         estimate = m2)[1,3],
         
         f_meas(skep_simdata_pred_2,
         truth = Diagnosis,
         estimate = m)[1,3],
         f_meas(skep_simdata_pred_2,
         truth = Diagnosis,
         estimate = m1)[1,3],
         f_meas(skep_simdata_pred_2,
         truth = Diagnosis,
         estimate = m2)[1,3],
         
         f_meas(skep_simdata_pred_test_2,
         truth = Diagnosis,
         estimate = m)[1,3],
         f_meas(skep_simdata_pred_test_2,
         truth = Diagnosis,
         estimate = m1)[1,3],
         f_meas(skep_simdata_pred_test_2,
         truth = Diagnosis,
         estimate = m2)[1,3]
  )
)

fscores <- fscores %>% 
  mutate( score = as.numeric(score))

```

```{r}
#visualise accuracy

fscores %>% 
  ggplot(aes(x=model, y = score, group = test, color = test))+
  geom_point()+ 
  geom_line()+
  facet_wrap(~set)+
  geom_hline(yintercept = .5, linetype = 2)+
  theme_bw()
```

Feature importance
```{r}
pacman::p_load(DALEX,DALEXtra)
```
```{r}
d_inf <- inf_simdata_train %>% 
  mutate(Diagnosis = as.factor(Diagnosis))

Logistic_inf <- logistic_reg() %>% 
  set_mode("classification") %>% 
  set_engine("glm") %>% 
  fit(Diagnosis ~ . , data = d_inf)
```
```{r}
explainer_lm <-
  explain_tidymodels(
    Logistic_inf,
    data = d_inf,
    y = as.numeric(d_inf$Diagnosis) - 1,
    label = "logReg",
    verbose = F
  )
explainer_lm %>% 
  model_parts() %>% 
  plot(show_boxplots = F )+
  ggtitle("Feature Importance","")
```


## Part III - Applying the ML pipeline to empirical data

Download the empirical dataset from brightspace and apply your ML pipeline to the new data, adjusting where needed. Warning: in the simulated dataset we only had 10 features, now you have many more! Such is the life of the ML practitioner. Consider the impact a higher number of features will have on your ML inference, and decide whether you need to cut down the number of features before running the pipeline (or alternatively expand the pipeline to add feature selection).

Data: https://www.dropbox.com/s/7ky1axvea33lgye/Ass3_empiricalData1.csv?dl=0
```{r}

```


